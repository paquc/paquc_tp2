Train data size: 80, Validation size: 0, Test size: 20

./BGL_Brain_results/BGL_60min_1_alarm_occurences_matrix_preprocessed_corr.csv

Data sample 0 - Start index: 0, End index: 843, Chunk size: 843

------------------------------------
--- Random Forest Classifier - TEST DATA - 0 ---

Size of test set: 168
Size of predicted set: 168

Number of estimators: 10
Randomize value: 55

Unique classes in TESTS\VALIDATION set: [0 1]
Unique classes in PREDICTED set: [0 1]

Accuracy: 0.7262
Recall: 0.96
AUC: 0.75
Mean Absolute Error (MAE): 0.27
R-squared: -0.11
              precision    recall  f1-score   support

           0       0.94      0.54      0.68        93
           1       0.63      0.96      0.76        75

    accuracy                           0.73       168
   macro avg       0.78      0.75      0.72       168
weighted avg       0.80      0.73      0.72       168

Caracteristiques les plus importantes:
Feature  Importance
     E1    0.169968
   E346    0.100128
   E172    0.063563
   E120    0.059909
   E260    0.035987
   E413    0.034607
   E419    0.032616
   E371    0.031122
   E190    0.028365
   E118    0.027867
   E307    0.026388
   E370    0.025535
   E137    0.020617
   E183    0.020541
   E442    0.019160
   E340    0.018549
   E216    0.016657
   E184    0.015924
   E339    0.013833
   E140    0.013248
   E213    0.013246
   E456    0.013091
   E174    0.012943
   E452    0.012901
   E200    0.012748
   E242    0.012705
   E353    0.010930
   E352    0.010003
   E384    0.008254
   E114    0.008042
    E12    0.007800
    E17    0.007717
   E133    0.007419
    E15    0.007214
   E221    0.007002
   E116    0.005910
    E10    0.005380
   E186    0.004941
   E245    0.004578
   E136    0.004300
   E318    0.003639
   E400    0.003514
   E507    0.003504
   E122    0.003161
   E218    0.003056
   E403    0.003013
   E468    0.002833
    E18    0.002801
   E445    0.002690
     E8    0.002383
   E105    0.002141
   E115    0.001978
   E421    0.001927
   E178    0.001690
   E211    0.001676
   E321    0.001301
   E134    0.001256
   E268    0.001208
   E156    0.001105
   E131    0.000993
   E388    0.000896
   E433    0.000361
   E271    0.000280
   E382    0.000275
   E135    0.000168
   E241    0.000093
   E274    0.000077
   E262    0.000066
   E276    0.000063
   E288    0.000041
   E297    0.000039
   E386    0.000038
   E217    0.000012
    E14    0.000006
   E287    0.000002
   E277    0.000002
   E285    0.000000
   E272    0.000000
   E273    0.000000
   E266    0.000000
   E281    0.000000
   E279    0.000000
   E278    0.000000
   E275    0.000000
   E270    0.000000
   E264    0.000000
   E265    0.000000
   E226    0.000000
   E252    0.000000
   E250    0.000000
   E162    0.000000
   E163    0.000000
   E164    0.000000
   E165    0.000000
   E195    0.000000
   E123    0.000000
   E267    0.000000
   E269    0.000000
   E251    0.000000
   E261    0.000000
   E263    0.000000
   E295    0.000000
   E327    0.000000
    E39    0.000000
    E40    0.000000
    E36    0.000000
    E38    0.000000
    E35    0.000000
    E31    0.000000
   E328    0.000000
    E34    0.000000
   E302    0.000000
   E298    0.000000
   E286    0.000000
    E45    0.000000
    E47    0.000000
   E486    0.000000
    E49    0.000000
    E46    0.000000
    E50    0.000000
   E508    0.000000
    E55    0.000000
    E52    0.000000
    E63    0.000000
    E70    0.000000
    E77    0.000000
    E57    0.000000
    E78    0.000000
    E79    0.000000
    E81    0.000000
    E83    0.000000
    E87    0.000000
    E88    0.000000
    E93    0.000000
    E97    0.000000
------------------------------------

